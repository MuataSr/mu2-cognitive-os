# Mu2 Cognitive OS - Environment Variables
# ========================================
# Copy this file to .env and configure as needed

# ============================================================================
# Supabase Configuration
# ============================================================================
# Get these values from Supabase Dashboard → Settings → API
NEXT_PUBLIC_SUPABASE_URL=https://xxxxxxxxxxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# Database Connection String (from Supabase Dashboard → Settings → Database)
# Use the "URI" tab connection string with your database password
DATABASE_URL=postgresql://postgres:[YOUR-PASSWORD]@db.xxxxxxxx.supabase.co:5432/postgres

# ============================================================================
# Local Docker Postgres (Legacy - for local development only)
# ============================================================================
POSTGRES_PASSWORD=your-super-secret-and-long-postgres-password
JWT_SECRET=your-super-secret-jwt-token-with-at-least-32-characters-long
API_EXTERNAL_URL=http://localhost:9999
SITE_URL=http://localhost:3000

# Service Ports
STUDIO_PORT=3000
DB_PORT=54322
AUTH_PORT=9999
REST_PORT=3001
REALTIME_PORT=4000
STORAGE_PORT=5000
BRAIN_PORT=8000

# ============================================================================
# API Configuration
# ============================================================================
# Frontend API Configuration (local backend)
NEXT_PUBLIC_API_URL=http://localhost:8000

# ============================================================================
# External APIs
# ============================================================================
# LibreTexts ADAPT API (Optional)
LIBRETEXTS_API_URL=https://adapt.libretexts.org/api
LIBRETEXTS_API_KEY=

# ============================================================================
# Local LLM Configuration (Ollama - for anonymization + fallback)
# ============================================================================
LLM_PROVIDER=ollama
LLM_MODEL=gemma3:270m
LLM_BASE_URL=http://localhost:11434

# ============================================================================
# Hybrid LLM Configuration (FERPA Compliant: Local Anonymization + Cloud)
# ============================================================================
# Enable hybrid mode
LLM_HYBRID_MODE=true

# Anonymization Settings (ALWAYS ON for FERPA compliance)
LLM_ANONYMIZATION_ENABLED=true
ANONYMIZATION_METHOD=hybrid
ANONYMIZATION_LOG_ENABLED=false

# Cloud LLM Provider Configuration
# Using Abacus AI (OpenAI-compatible) - Get your key at: https://abacus.ai/
LLM_CLOUD_PROVIDER=custom
LLM_CLOUD_API_KEY=your-abacus-api-key-here
LLM_CLOUD_BASE_URL=https://routellm.abacus.ai/v1
LLM_CLOUD_MODEL=gpt-4o-mini

# Alternative: OpenAI
# LLM_CLOUD_PROVIDER=openai
# LLM_CLOUD_API_KEY=your-openai-api-key
# LLM_CLOUD_BASE_URL=https://api.openai.com/v1
# LLM_CLOUD_MODEL=gpt-4o-mini

# Alternative: Minimax M2.1
# LLM_CLOUD_PROVIDER=minimax
# LLM_CLOUD_API_KEY=your-minimax-api-key-here
# LLM_CLOUD_BASE_URL=https://api.minimax.chat/v1
# LLM_CLOUD_MODEL=M2-her

# Hybrid Routing Settings
LLM_CLOUD_THRESHOLD=0.7
LLM_FORCE_CLOUD_FOR=generation
LLM_LOCAL_ONLY_FOR=embedding

# Embeddings (Local Only - for privacy)
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSION=768

# ============================================================================
# Storage Configuration (Legacy)
# ============================================================================
STORAGE_REGION=us-east-1
STORAGE_BUCKET=mu2-cortex-storage
DB_ENC_KEY=supabaserealtime
